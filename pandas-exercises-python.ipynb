{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "e    3\n",
      "d    4\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#how to create a series from a list, numpy array and dict?\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser1 = pd.Series(mylist)\n",
    "ser2 = pd.Series(myarr)\n",
    "ser3 = pd.Series(mydict)\n",
    "print(ser3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index  0\n",
       "0     a  0\n",
       "1     b  1\n",
       "2     c  2\n",
       "3     e  3\n",
       "4     d  4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to convert the index of a series into a columns of a dataframes?\n",
    "ser = pd.Series(mydict)\n",
    "df = ser.to_frame().reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2\n",
       "0    a     0\n",
       "1    b     1\n",
       "2    c     2\n",
       "3    e     3\n",
       "4    d     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to combine many series to from a dataframe? \n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "# Solution 1\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "df.head()\n",
    "# Solution 2 \n",
    "df = pd.DataFrame({'col1': ser1, 'col2': ser2})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    e\n",
       "4    d\n",
       "Name: alphabets, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to assign name to the series index?\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser.name = 'alphabets'\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get items of series A not present in series B?\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # How to get the items not common to both series A and series B?\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "ser_u = pd.Series(np.union1d(ser1, ser2)) #union\n",
    "ser_i = pd.Series(np.intersect1d(ser1, ser2)) #intersect\n",
    "ser_u[~ser_u.isin(ser_i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25117263,  7.70986507, 10.92259345, 13.36360403, 18.0949083 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get the minimum, 25th percentile, median, 75th, and max of numeric series?\n",
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "state = np.random.RandomState(100)\n",
    "ser = pd.Series(state.normal(10, 5, 25))\n",
    "np.percentile(ser, q=[0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    8\n",
       "c    7\n",
       "g    5\n",
       "h    5\n",
       "d    2\n",
       "e    2\n",
       "a    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get frequency counts of unique items of a series?\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size = 30)))\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Freq: 3    7\n",
      "2    2\n",
      "4    2\n",
      "1    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         3\n",
       "2         3\n",
       "3         3\n",
       "4         3\n",
       "5     Other\n",
       "6     Other\n",
       "7         3\n",
       "8         3\n",
       "9         2\n",
       "10        3\n",
       "11    Other\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to keep only top 2 most frequent values as it is and replace everything else as 'Other'?\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "print('Top 2 Freq:', ser.value_counts())\n",
    "ser[~ser.isin(ser.value_counts().index[0:2])] = 'Other'\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.792632\n",
      "1    0.970528\n",
      "2    0.831602\n",
      "3    0.049370\n",
      "4    0.209661\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     8th\n",
       "1    10th\n",
       "2    10th\n",
       "3     2nd\n",
       "4     3rd\n",
       "dtype: category\n",
       "Categories (10, object): ['1st' < '2nd' < '3rd' < '4th' ... '7th' < '8th' < '9th' < '10th']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to bin a numeric series to 10 groups of equal size?\n",
    "ser = pd.Series(np.random.random(20))\n",
    "print(ser.head())\n",
    "pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "        labels = ['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th','9th', '10th']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  1  6  1  3  8\n",
       "1  8  5  4  1  3\n",
       "2  7  9  5  2  5\n",
       "3  9  7  2  3  1\n",
       "4  2  7  2  9  6\n",
       "5  4  5  3  4  1\n",
       "6  3  7  3  9  2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to convert a numpy array to a dataframe of given shape\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    7\n",
       "2    6\n",
       "3    9\n",
       "4    7\n",
       "5    6\n",
       "6    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to find the positions of numbers that are multiples of 3 from a series?\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "ser\n",
    "#np.argwhere(ser % 3 == 0)\n",
    "# i can't solve the problem, i will look again later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to extract items at given position from a series\n",
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\1222463864.py:5: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ser1.append(ser2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  a\n",
       "1  1  b\n",
       "2  2  c\n",
       "3  3  d\n",
       "4  4  e"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to stack two series vertically and horizontally?\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "# Vertical\n",
    "ser1.append(ser2)\n",
    "# Horizontal\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get positions of items of series A in another series B?\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "# Solution 1\n",
    "[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "# Solution 2\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3302642479491031"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to compute the mean squared error on an truth and predicted series?\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to calculate the number of characters in each word in a series?\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "ser.map(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 3.0, 6.0, 6.0, 6.0, 8.0]\n",
      "[nan, nan, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# How to compute difference of differences between consequtive numbers of a series?\n",
    "ser = pd.Series([1, 3 , 6, 9, 15, 21, 27, 35])\n",
    "print(ser.diff().tolist())\n",
    "print(ser.diff().diff().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to convert a series of date-string to a timeseries?\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))\n",
    "# Solution 2\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week number:  [53, 5, 9, 14, 19, 23]\n",
      "Day number of year:  [1, 33, 63, 94, 125, 157]\n",
      "Day of week:  [4, 2, 5, 3, 0, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\1222662970.py:8: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  print('Week number: ', ser_ts.dt.weekofyear.tolist())\n"
     ]
    }
   ],
   "source": [
    "# How to get the day of month, week number, day of year and day of week from a series of date strings?\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "# day of month\n",
    "print('Date: ', ser_ts.dt.day.tolist())\n",
    "# week number\n",
    "print('Week number: ', ser_ts.dt.weekofyear.tolist())\n",
    "# day of year\n",
    "print('Day number of year: ', ser_ts.dt.dayofyear.tolist())\n",
    "# day of week\n",
    "print('Day of week: ', ser_ts.dt.day_of_week.tolist())\n",
    "# i can't solve 'day of week', i will look again later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to convert year-month string to dates corresponding to the 4th day of the month?\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str')+ '-' + '04'\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]\n",
    "# Solution 2\n",
    "ser.map(lambda x: parse('04' + x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to filter words that contaion atleast 2 vowels from a series?\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0)for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to filter valid emails from a series ?\n",
    "emails = pd.Series(['buying book at amozom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "#pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "# Solution 1\n",
    "import re\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails[mask]\n",
    "# Solution 2\n",
    "emails.str.findall(pattern, flags=re.IGNORECASE)\n",
    "# Solution 3\n",
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "['carrot', 'banana', 'apple', 'carrot', 'banana', 'apple', 'carrot', 'apple', 'carrot', 'apple']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "apple     6.75\n",
       "banana    3.50\n",
       "carrot    5.25\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get the mena of a series grouped by another series?\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weight = pd.Series(np.linspace(1, 10, 10))\n",
    "print(weight.tolist())\n",
    "print(fruit.tolist())\n",
    "weight.groupby(fruit).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to compute the euclidean distance between two series?\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "# Solution\n",
    "sum((p - q)**2)**.5\n",
    "# Solution(using func)\n",
    "np.linalg.norm(p-q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to find all the local maxina(or peaks) in a numeric series?\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    3\n",
      "     3\n",
      "e    3\n",
      "a    2\n",
      "c    1\n",
      "g    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dbcgdebgabedggade'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to replace missing spaces in a string with the least frequent character?\n",
    "my_str = 'dbc deb abed gade'\n",
    "ser = pd.Series(list('dbc deb abed gade'))\n",
    "freq = ser.value_counts()\n",
    "print(freq)\n",
    "least_freq = freq.dropna().index[-1]\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    1\n",
       "2000-01-08    3\n",
       "2000-01-15    5\n",
       "2000-01-22    1\n",
       "2000-01-29    6\n",
       "2000-02-05    8\n",
       "2000-02-12    2\n",
       "2000-02-19    3\n",
       "2000-02-26    1\n",
       "2000-03-04    9\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to create a TimeSeris starting '2000-01-01' and 10 weekends(saturdays) after that having random numbers as values?\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq = 'W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n",
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)\n",
    "ser = pd.Series([1,10,3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "# Solution\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "\n",
    "# Alternatives\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21, 0.34, 0.05, 0.54, 0.59, 0.24, 0.25, -0.2, 0.35, 0.01]\n",
      "Lag having highest correlation:  5\n"
     ]
    }
   ],
   "source": [
    "# How to compute the autocorrelations of a numeric series?\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n",
      "C:\\Users\\fatih\\AppData\\Local\\Temp\\ipykernel_7872\\846289175.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(chunk.iloc[0,:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
      "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "50   0.08873  21.0   5.64   0.0  0.439  5.963  45.7  6.8147  4.0  243.0   \n",
      "100  0.14866   0.0   8.56   0.0  0.520  6.727  79.9  2.7778  5.0  384.0   \n",
      "150  1.65660   0.0  19.58   0.0  0.871  6.122  97.3  1.6180  5.0  403.0   \n",
      "200  0.01778  95.0   1.47   0.0  0.403  7.135  13.9  7.6534  3.0  402.0   \n",
      "\n",
      "     ptratio       b  lstat  medv  \n",
      "0       15.3  396.90   4.98  24.0  \n",
      "50      16.8  395.56  13.45  19.7  \n",
      "100     20.9  394.76   9.42  27.5  \n",
      "150     14.7  372.80  14.10  21.5  \n",
      "200     17.0  384.30   4.45  32.9  \n",
      "        crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
      "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "50   0.08873  21.0   5.64   0.0  0.439  5.963  45.7  6.8147  4.0  243.0   \n",
      "100  0.14866   0.0   8.56   0.0  0.520  6.727  79.9  2.7778  5.0  384.0   \n",
      "150  1.65660   0.0  19.58   0.0  0.871  6.122  97.3  1.6180  5.0  403.0   \n",
      "200  0.01778  95.0   1.47   0.0  0.403  7.135  13.9  7.6534  3.0  402.0   \n",
      "\n",
      "     ptratio       b  lstat  medv  \n",
      "0       15.3  396.90   4.98  24.0  \n",
      "50      16.8  395.56  13.45  19.7  \n",
      "100     20.9  394.76   9.42  27.5  \n",
      "150     14.7  372.80  14.10  21.5  \n",
      "200     17.0  384.30   4.45  32.9  \n"
     ]
    }
   ],
   "source": [
    "#How to import only every nth row from a csv file to create a dataframe?\n",
    "# Solution 1: Use chunks and for-loop\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.DataFrame()\n",
    "for chunk in df:\n",
    "    df2 = df2.append(chunk.iloc[0,:])\n",
    "print(df2.head())\n",
    "\n",
    "\n",
    "# Solution 2: Use chunks and list comprehension\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n",
    "print(df2.head())\n",
    "# Solution 3: Use csv reader\n",
    "#import csv          \n",
    "#with open('BostonHousing.csv', 'r') as f:\n",
    "#    reader = csv.reader(f)\n",
    "#   out = []\n",
    "#    for i, row in enumerate(reader):\n",
    "#        if i%50 == 0:\n",
    "#            out.append(row)\n",
    "\n",
    "#df2 = pd.DataFrame(out[1:], columns=out[0])\n",
    "#print(df2.head())\n",
    "# i can't solve the problem, i will look again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to create a dataframe with rows as strides from a given series?\n",
    "L = pd.Series(range(15))\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "# How to import only specified columns from a csv file?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n",
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n",
      "float64    18\n",
      "object      9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How to get the nrows, ncolumns, datatype, summary stats of each columns of a dataframe?\n",
    "# Also get the array and list equivalent.\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "# number of rows and columns\n",
    "print(df.shape)\n",
    "# datatypes\n",
    "print(df.dtypes)\n",
    "# how many columns under each dtype\n",
    "print(df.dtypes.value_counts())\n",
    "# summary statisctics\n",
    "df_stats = df.describe()\n",
    "# numpy array\n",
    "df_arr = df.values\n",
    "# list\n",
    "df_list = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to extract the row and column number of a particular cell with given criterion?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "# Solution\n",
    "# Get Manufacturer with highest price\n",
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n",
    "# Get Row and Columns number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "#df.get_value(row[0], 'Price')\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers. \n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'Type', 'Min.Price', 'Price', 'Max.Price',\n",
      "       'MPG.city', 'MPG.highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev.per.mile', 'Man.trans.avail',\n",
      "       'Fuel.tank.capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn.circle', 'Rear.seat.room', 'Luggage.room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n",
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# How to rename a specific columns in a dataframe?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "print(df.columns)\n",
    "# Solution\n",
    "# Step1\n",
    "df = df.rename(columns = {'Type': 'CarType'})\n",
    "# or \n",
    "df.columns.values[2] = 'CarType'\n",
    "# Step2\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# How to check if a dataframe has any missing values?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "print(df.isnull().values.any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to count the number of missing values in each column?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "n_missing_each_col = df.apply(lambda x: x.isnull().sum())\n",
    "n_missing_each_col.argmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "# How to replace missing values of multiple numeric columns with the mean?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use apply function on existing columns with global variables as additional arguments?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to select a specific columns from a dataframe as a dataframe instead of a series?\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "type(df[['a']])\n",
    "type(df.loc[:, ['a']])\n",
    "type(df.iloc[:, [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to change the order of columns of a dataframe?\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "# Solution Q1\n",
    "df[list['cbade']]\n",
    "#Solution Q2 - No hard coding\n",
    "def switch_columns(df, col1=None, col2=None):\n",
    "    colnames = df.columns.tolist()\n",
    "    i1, i2 = colnames.index(col1), colnames.index(col2)\n",
    "    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n",
    "    return df[colnames]\n",
    "df1 = switch_columns(df, 'a', 'c')\n",
    "# Solution Q3\n",
    "df[sorted(df.columns)]\n",
    "# or\n",
    "df.sort_index(axis=1, ascending=False, inplace=True)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>...</th>\n",
       "      <th>Rear.seat.room</th>\n",
       "      <th>Luggage.room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>...</td>\n",
       "      <td>26.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.7</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Eurovan</td>\n",
       "      <td>Van</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.7</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volkswagen Eurovan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>Compact</td>\n",
       "      <td>17.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Passat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Corrado</td>\n",
       "      <td>Sporty</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Corrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>240</td>\n",
       "      <td>Compact</td>\n",
       "      <td>21.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>850</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>24.8</td>\n",
       "      <td>26.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manufacturer    Model     Type  Min.Price  Price  ...  Rear.seat.room  \\\n",
       "0         Acura  Integra    Small       12.9   15.9  ...            26.5   \n",
       "1           NaN   Legend  Midsize       29.2   33.9  ...            30.0   \n",
       "2          Audi       90  Compact       25.9   29.1  ...            28.0   \n",
       "3          Audi      100  Midsize        NaN   37.7  ...            31.0   \n",
       "4           BMW     535i  Midsize        NaN   30.0  ...            27.0   \n",
       "..          ...      ...      ...        ...    ...  ...             ...   \n",
       "88   Volkswagen  Eurovan      Van       16.6   19.7  ...            34.0   \n",
       "89   Volkswagen   Passat  Compact       17.6   20.0  ...            31.5   \n",
       "90   Volkswagen  Corrado   Sporty       22.9   23.3  ...            26.0   \n",
       "91        Volvo      240  Compact       21.8   22.7  ...            29.5   \n",
       "92          NaN      850  Midsize       24.8   26.7  ...            30.0   \n",
       "\n",
       "    Luggage.room  Weight   Origin                Make  \n",
       "0            NaN  2705.0  non-USA       Acura Integra  \n",
       "1           15.0  3560.0  non-USA        Acura Legend  \n",
       "2           14.0  3375.0  non-USA             Audi 90  \n",
       "3           17.0  3405.0  non-USA            Audi 100  \n",
       "4           13.0  3640.0  non-USA            BMW 535i  \n",
       "..           ...     ...      ...                 ...  \n",
       "88           NaN  3960.0      NaN  Volkswagen Eurovan  \n",
       "89          14.0  2985.0  non-USA   Volkswagen Passat  \n",
       "90          15.0  2810.0  non-USA  Volkswagen Corrado  \n",
       "91          14.0  2985.0  non-USA           Volvo 240  \n",
       "92          15.0  3245.0  non-USA           Volvo 850  \n",
       "\n",
       "[93 rows x 27 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to set the number of rows and columns displayed in the output?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "# Solution\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "df\n",
    "# Show all available options\n",
    "#pd.describe_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.0002\n",
      "1  0.0000\n",
      "2  0.0000\n",
      "3  0.0537\n"
     ]
    }
   ],
   "source": [
    "# How to format or suppress scientific notations in a pandas dataframe?\n",
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "#df\n",
    "# Solution 1: Rounding\n",
    "#df.round(4)\n",
    "# Solution 2: Use apply to change format\n",
    "df.apply(lambda x: '%.4f' % x, axis=1)\n",
    "#or\n",
    "df.applymap(lambda x: '%.4f' % x)\n",
    "# Solution 3: Use set_option\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "# Solution 4: Assign display.float_format\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(df)\n",
    "# Reset/undo float formatting\n",
    "pd.options.display.float_format = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7f8fd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7f8fd_level0_col0\" class=\"col_heading level0 col0\" >random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7f8fd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7f8fd_row0_col0\" class=\"data row0 col0\" >2.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f8fd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7f8fd_row1_col0\" class=\"data row1 col0\" >91.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f8fd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7f8fd_row2_col0\" class=\"data row2 col0\" >33.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7f8fd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7f8fd_row3_col0\" class=\"data row3 col0\" >88.65%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25b00355fc0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to format all the values in a dataframe as percentages?\n",
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "\n",
    "# Solution\n",
    "out = df.style.format({\n",
    "    'random': '{0:.2%}'.format,\n",
    "})\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "# How to filter every nth row in a dataframe ?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# How create a primary key index by combining relevant columns?\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\n",
    "df.index = df.Manufacturer + '_' + df.Model + '_' + df.Type\n",
    "print(df.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get the row number of the nth largest value in a column?\n",
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n",
    "n = 5\n",
    "df['a'].argsort()[::-1][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser:  [93, 48, 12, 17, 48, 85, 69, 40, 97, 61, 24, 56, 15, 8, 96] mean:  51\n"
     ]
    }
   ],
   "source": [
    "# How to find the position of the nth largest value greater than a given value?\n",
    "from pandas import array\n",
    "\n",
    "\n",
    "ser = pd.Series(np.random.randint(1, 100, 15))\n",
    "print('ser: ', ser.tolist(), 'mean: ', round(ser.mean()))\n",
    "#np.argwhere(ser > ser.mean())[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to get the last n rows of a dataframe with row sum > 100?\n",
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "# print rows sums\n",
    "rowsums = df.apply(np.sum, axis=1)\n",
    "#last two rows with row sum greater than 100\n",
    "last_two_rows = df.iloc[np.where(rowsums > 100)[0][-2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 %ile:  0.016049294076965887 | 0.95 %ile:  63.87667222018393\n"
     ]
    }
   ],
   "source": [
    "# How to find and cap outliers from a seris or dataframe columns?\n",
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "def cap_outliers(ser, low_perc, high_perc):\n",
    "    low, high = ser.quantile([low_perc, high_perc])\n",
    "    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high)\n",
    "    ser[ser < low] = low\n",
    "    ser[ser > high] = high\n",
    "    return(ser)\n",
    "\n",
    "capped_ser = cap_outliers(ser, .05, .95)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32. 33. 29. 48. 24. 40. 38. 13.]\n",
      " [26. 46. 31.  8. 16. 30. 15. 48.]\n",
      " [21. 24. 27. 46. 48. 22. 10. 48.]\n",
      " [14. 28. 20. 24. 30. 10. 43. 47.]\n",
      " [13. 17. 10. 11. 43. 39. 46. 27.]\n",
      " [17. 46. 12. 35. 45. 36. 36. 24.]\n",
      " [47. 45. 33. 44. 25. 40. 24. 20.]\n",
      " [32. 20. 25.  9. 12. 35. 47. 25.]]\n"
     ]
    }
   ],
   "source": [
    "# How to reshape a dataframe to the largest possible square after removing the negative values?\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10, -1))\n",
    "# Step 1: remove negative values from arr\n",
    "arr = df[df > 0].values.flatten()\n",
    "arr_qualified = arr[~np.isnan(arr)]\n",
    "# Step 2: find side_lenght of largest possible square\n",
    "n = int(np.floor(arr_qualified.shape[0]**.5))\n",
    "# Step 3: Take top n^2 items without changing positions\n",
    "top_indexes = np.argsort(arr_qualified)[::-1]\n",
    "output = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1  10  11  12  13  14\n",
      "2   5   6   7   8   9\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "# How to swap two rows of a dataframe?\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "def swap_rows(df1, i1, i2):\n",
    "    a,  b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy()\n",
    "    df.iloc[i1, :], df.iloc[i2, :] = b, a\n",
    "    return df\n",
    "print(swap_rows(df, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "4  20  21  22  23  24\n",
      "3  15  16  17  18  19\n",
      "2  10  11  12  13  14\n",
      "1   5   6   7   8   9\n",
      "0   0   1   2   3   4\n"
     ]
    }
   ],
   "source": [
    "# How to reverse the rows of dataframe?\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "# Solution 1\n",
    "df.iloc[::-1, :]\n",
    "# Solution 2\n",
    "print(df.loc[df.index[::-1], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  5  10  15  20   b   c   d   e\n",
      "0  1  0   0   0   0   1   2   3   4\n",
      "1  0  1   0   0   0   6   7   8   9\n",
      "2  0  0   1   0   0  11  12  13  14\n",
      "3  0  0   0   1   0  16  17  18  19\n",
      "4  0  0   0   0   1  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "# How to create one-hot encodings of a categorical variable(dummy variables)?\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1), columns=list('abcde'))\n",
    "df_onehot = pd.concat([pd.get_dummies(df['a']), df[list('bcde')]], axis=1)\n",
    "print(df_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with highest row maxes:  0\n"
     ]
    }
   ],
   "source": [
    "# Which columns contains the highest number of row_wise maxiumum values?\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 40).reshape(10, -1))\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    p   q   r   s nearest_row  dist\n",
      "a  37  84  21  59           e    97\n",
      "b  59  53  52  85           g    93\n",
      "c  77  27  53  64           j    84\n",
      "d  17  37  15  85           g   109\n",
      "e  74  36  96  64           d   101\n",
      "f  48  50  43  90           g    98\n",
      "g  88  44  21   3           j   115\n",
      "h  69  26  22  54           j    89\n",
      "i  65  20   4  28           j   109\n",
      "j  20  87  59  76           g   115\n"
     ]
    }
   ],
   "source": [
    "# How to create a new columns that contains the row number of nearest column by euclidean distance?\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "import numpy as np\n",
    "# init outputs\n",
    "nearest_rows = []\n",
    "nearest_distance = []\n",
    "# iterate rows\n",
    "for i, row in df.iterrows():\n",
    "    curr = row\n",
    "    rest = df.drop(i)\n",
    "    e_dists = {} # init dict to store euclidean dists for current row.\n",
    "    # irerate rest of rows for current row\n",
    "    for j, contestant in rest.iterrows():\n",
    "        # compute euclidean dist and update e_dists\n",
    "        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n",
    "    # update nearest row to current row and the distance value\n",
    "    nearest_rows.append(max(e_dists, key=e_dists.get))\n",
    "    nearest_distance.append(max(e_dists.values()))\n",
    "\n",
    "df['nearest_row'] = nearest_rows\n",
    "df['dist'] = nearest_distance\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4710a83545741eb845e39d42f17946b18e65be580c75e0ca94b4f9fab7f0d016"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
